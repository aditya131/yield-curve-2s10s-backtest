{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc215c3a-98ff-4984-b397-c22276ee97cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as pdr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d485f4c-c862-47e9-857c-e196e34e68c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime(2020,1,1)\n",
    "end = datetime.datetime.today()\n",
    "df = pd.DataFrame()                                          #Creates Dataframe\n",
    "df['2Y'] = pdr.DataReader('DGS2', 'fred', start, end)        #Fetches 2s Data from fred\n",
    "df['10Y'] = pdr.DataReader('DGS10', 'fred', start, end)      #Fetches 10s Data from fred\n",
    "df.dropna(inplace = True)\n",
    "df['Spread'] = df['10Y'] - df['2Y']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe55ae17-c709-44c1-8630-cd487a19d9cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe with Macro Filter: 0.0\n",
      "Signal_macro counts:\n",
      "Signal_macro\n",
      " 0    949\n",
      " 1    257\n",
      "-1    138\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample rows around potential entries:\n",
      "                   Z  Signal  HikeRegime  EaseRegime  Signal_macro\n",
      "DATE                                                              \n",
      "2020-05-26  1.106487      -1       False       False             0\n",
      "2020-05-28  1.203625      -1       False       False             0\n",
      "2020-06-01  1.094784      -1       False       False             0\n",
      "2020-06-02  1.006628      -1       False       False             0\n",
      "2020-06-03  1.453484      -1       False       False             0\n",
      "2020-06-04  1.745652      -1       False       False             0\n",
      "2020-06-05  2.078148      -1       False       False             0\n",
      "2020-06-08  1.828394      -1       False       False             0\n",
      "2020-06-09  1.656141      -1       False       False             0\n",
      "2020-06-10  1.243678      -1       False       False             0\n",
      "\n",
      "PnL_macro summary:\n",
      "count    1244.000000\n",
      "mean        0.000200\n",
      "std         4.783609\n",
      "min       -32.214740\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max        59.502326\n",
      "Name: PnL_macro, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Creating a rolling window, a time period in which we want to compare results \n",
    "#Like for a 10 day Moving average, rolling window is 10,so it keeps on calculating 10 day MA for the last 10 days as we move on each day\n",
    "\n",
    "window = 100\n",
    "df['Spread_Mean'] = df['Spread'].rolling(window).mean()\n",
    "df['Spread_Std'] = df['Spread'].rolling(window).std()\n",
    "df['Z'] = (df['Spread'] - df['Spread_Mean'])/df['Spread_Std']\n",
    "\n",
    "#Signal : Buy Steepner when z score is -1 and buy flattener when z score is 1, mean reversion trades in essense\n",
    "df['Signal'] = np.where(df['Z'] < -1, 1, np.where(df['Z'] > 1, -1, 0))         #A multi question, where we are saying is z_score < -1, then signal is 1(steepener)\n",
    "\n",
    "#Scale position size with z-score intensity( large size for large z-score because its a mean reversion strategy, and large outsized move means higher chnces of getting back to mean)\n",
    "#It is capped at 3 so that we dont crazy size on any trade\n",
    "\n",
    "df['Position'] = df['Signal']*np.clip(df['Z'].abs(),0,3)  #Taking absolute score of z and capping it to 3, so for z = 1.8, Position is 1.8 for signal -1 (Flattener)\n",
    "                                                         #For z = -2.5, Position is 2,5 with Signal +1 (Steepener)\n",
    "\n",
    "\n",
    "#Computing pnl using DV01 \n",
    "DV01 = 100            # Assume for every 1bps move, 100 USD profit/loss          \n",
    "df['Spread_Change'] = df['Spread'].diff()\n",
    "\n",
    "#PnL = Positon on previous day * change in spread * DV01\n",
    "df['PnL'] = df['Position'].shift(1) * df['Spread_Change'] * DV01\n",
    "df['CumPnL'] = df['PnL'].cumsum()\n",
    "\n",
    "\n",
    "#Is z_score is greater than 1, then signal is -1(flattener); otherwise 0(no trade)\n",
    "# # 1) Pull the monthly series\n",
    "ff = pdr.DataReader('FEDFUNDS', 'fred', start, end)\n",
    "\n",
    "# Reindex onto your daily df index and forward-fill\n",
    "df['FF'] = ff.reindex(df.index).ffill()\n",
    "\n",
    "# (Optional) back-fill the very first days if you care  \n",
    "# df['FF'].bfill(inplace=True))\n",
    "\n",
    "# 2) Compute 63-day MA and the two regimes\n",
    "df['FF_MA63']    = df['FF'].rolling(63).mean()\n",
    "df['HikeRegime'] = df['FF'] > df['FF_MA63']    # good for steepeners\n",
    "df['EaseRegime'] = df['FF'] < df['FF_MA63']    # good for flatteners\n",
    "\n",
    "# 3) Gate your original z-score signal by regime\n",
    "#    (df['Signal'] is +1 for steep, â€“1 for flat, 0 otherwise)\n",
    "df['Signal_steep'] = np.where((df['Signal'] ==  1) & df['HikeRegime'],  1, 0)\n",
    "df['Signal_flat']  = np.where((df['Signal'] == -1) & df['EaseRegime'],  -1, 0)\n",
    "df['Signal_macro'] = df['Signal_steep'] + df['Signal_flat']\n",
    "\n",
    "# 4) Position sizing (same z-score scaling/cap)\n",
    "df['Position_macro'] = df['Signal_macro'] * np.clip(df['Z'].abs(), 0, 3)\n",
    "\n",
    "# 5) PnL and cumulative PnL\n",
    "df['PnL_macro']    = df['Position_macro'].shift(1) * df['Spread_Change'] * DV01\n",
    "df['CumPnL_macro'] = df['PnL_macro'].cumsum()\n",
    "\n",
    "# 6) Annualized Sharpe\n",
    "sharpe_macro = df['PnL_macro'].mean() / df['PnL_macro'].std() * np.sqrt(252)\n",
    "print(\"Sharpe with Macro Filter:\", round(sharpe_macro, 2))\n",
    "\n",
    "# 1) Do you ever get a non-zero macro signal?\n",
    "print(\"Signal_macro counts:\")\n",
    "print(df['Signal_macro'].value_counts(dropna=False))\n",
    "\n",
    "# 2) Peek at the first few rows where you *would* have entered\n",
    "print(\"\\nSample rows around potential entries:\")\n",
    "print(df[['Z','Signal','HikeRegime','EaseRegime','Signal_macro']].loc[\n",
    "    (df['Signal'] != 0) | (df['Signal_macro'] != 0)\n",
    "].head(10))\n",
    "\n",
    "# 3) Check your filtered PnL\n",
    "print(\"\\nPnL_macro summary:\")\n",
    "print(df['PnL_macro'].describe())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a2fc2f-0401-426a-af32-43ddb82de844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
